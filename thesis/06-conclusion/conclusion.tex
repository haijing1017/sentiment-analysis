In this final chapter we will summarize all the reasons for involving in such project, as well as the main contributions of the same. After listing the results we will address possible future improvements.

Nowadays with emerging markets and information flow it has become a necessity to try to predict future trends. Thus, companies are processing information luring through Internet with hope they will make a right choice. Big role in company's marketing strategy are social media channels, such as Facebook, Twitter or Instagram. Recognizing the potential use of customers input on the Web, companies have started gathering data related to their online advertisements. Logically, next step was to find a proper way of processing the data in order to discover certain correlations that could guide their production planning. One of recent methods for doing so is called sentiment analysis.

Our report consists of describing current trends in the field of sentiment analysis and how it is applied in business. Showing the reasons for using such method has brought us to the idea of investigating about available open source solutions. We have tried to make a comparison with some of sentiment analysis APIs on a given dataset which consists of Facebook comments related to a certain post about fashion industry products. The project itself consists of building a framework representing in a user-friendly way data that has been provided to us with obtained sentiment results of different APIs. We have made a comparison of each API on its original data and on data translated in English. Our statistical results have shown that APIs in general perform better when doing analysis of comments translated in English.

Another point where we have seen a potential improvement in our analysis was taking into consideration emojis or emoticons. Currently, emojis have been one of the easiest and most used way of communication. People have seen them as a fast, expressive enough version of typed text. Taking this into consideration we have investigated about finding a proper way to use power of emojis to improve our results. The most obvious solution was building a hash table of emoticons and their related English translations (for example :) equals happy). The idea of defining a such hash table has brought us to Emoji Sentiment Ranking which contains needed sentiment score for most of emoticons present in our dataset. For the ones missing the score we have identified a similar items from the rank table and assigned the same sentiment score.

After obtaining sentiment scores from different APIs on the various versions of the given data we were able to make a comparison between them. We were also able to show how a particular API performs on original data, data translated to English language and also on data taking emoji sentiment score into consideration.

In addition to the aspects analyzed by this work, there are several other points that can be deepened to improve our approach. We report in the following the ones we believe are the most important:

\section{Connecting to mining approaches – Applying clustering in sentiment analysis}

One of newer ideas in area of sentiment analysis is using clustering algorithms in order to obtain better sentiment analysis results, as explained in Using Clustering and Sentiment Analysis on Twitter\cite{Clustering}. Let's start with explaining what is clustering. Clustering is a method of splitting datasets into subsets of similar items based on the content of the items. In our case this would imply splitting different post sentences in the same "basket" depending on the content, which would result in groups of sentences talking about a similar product feature (product aspect). 
Clustering is an unsupervised learning method, which means that items are split in separate groups only based on similarity value calculated by its features (in this case the content of the posts). Different from classification method, where a model is trained based on past data, clustering method is based mostly on choosing an appropriate similarity measure. Another difference is that as output of classification original dataset is labeled with a class attribute, when in case of clustering, output is subsets of items. 

By applying clustering based sentiment analysis, we might obtain high accuracy results. The process would then be organized as follows : 
\begin{enumerate}
	\item Data gathering
	\item Data cleaning
	\item Computing the Term Frequency and Inverse Document Frequency
	\item Applying K-means clustering algorithm
	\item Sentiment Analysis Engine
\end{enumerate}

After the data is gathered, it would be good to find an automatic data cleaning method to will remove all the outliers from the dataset. When obtaining relatively noisy free data we should perform TF-IDF in order to determine keywords in the content that could possibly represent a feature of an analyzed product. TF stands for Term Frequency, represents how many times a term occurs in a document. IDF stands for Inverse Document Frequency, and represents how common is a term in all documents. 
After determining the keywords, we can have an idea of how many clusters we should expect in our dataset. This could be an input to the K-means algorithm, thus K-means chooses k random points as initial centroids and assigns all other points to the nearest centroid. Next step of the algorithm is re-centering the current centering. The process repeats until the next iteration produces same result as the previous iteration. Output of clustering method is set of clusters, where each cluster contains similar sentences. 

Output of the clustering step represents an input to the sentiment analysis engine. Each cluster is inserted in the engine to determine sentiment of people on a particular feature of the product.
Applied to our problem domain, the steps would go like so:
On each comment related to post, we would do data preprocessing, removing noisy data from the comment. Afterwards determining keywords in the comment related to the post. For example comment describing customers experience after using the product, such as a customer commenting on the fabric, quality, and color of the blouse. As input in K-mean we would have three aspects of product, in our case k would be 3. K-means would group all comment sentences related to each of the product features (quality, fabric and color). Afterwards, we apply the sentiment analysis on each cluster and obtain a sentiment value. This way we could calculate the overall sentiment value joining the cluster sentiment values, thus obtaining higher accuracy results.

Downsides of this approach:
\begin{enumerate}
	\item Applying method on large scale data
	\item Eliminating noisy data from social media content should usually involve human interaction
	\item Weaknesses of K-means method
\end{enumerate}

\section{Spam detection}

One of the future improvements could be finding a better method for spam detection in order to filter out noisy comments that could give us less accurate sentiment estimation.  How could we differ spam from comments that are related to a post? Spam is an unwanted content appearing in the stream of comments. By unwanted content we assume content not related to the post or any other comments of the post. For example, URLs leading to third party web pages used as advertisements or a person that is tagged without any other information about the post. It is in our favor to try to remove such content from the analysis set which could lead to better sentiment estimation. 

We can look at spam detection as one of data preprocessing techniques. Currently we have used Akismet for spam detection; it is a web service for recognizing spam comments. To be able to estimate the effectiveness of Akismet service, we have determined manually if a comment is a spam or not. Having a small comment dataset it was not time consuming to manually analyze the comments. After the analysis we have calculated the accuracy of chosen spam detection method. Unfortunately, the results have shown that on our dataset Akismet was not so effective.

\section{Out of the black box – Training a model}

Our project has been based on testing different APIs for sentiment analysis and determining which of the used APIs has given the best results. Using APIs as they are could be imagined as using a tool without knowing what is actually going on inside it. This way we could not tune the algorithm to suit our problem domain. By going out of the box, we could build a model that would provide us with better sentiment analysis results. 

Training a model can be seen as producing a function that applied on future data could give sentiment “class label”, in our case positive, negative or neutral value, with higher accuracy then the used APIs. The process of building a model consists of training a model on training set, validating the model and afterwards testing in on the test set. 
